{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker to robot base from trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = \"/home/pjlab/Franka_Tool/frankapy/logs/2024-09-22_14-12-28/log-000002-6876\"\n",
    "calibration_eyeinhand_results_dir = \"/home/pjlab/Franka_Tool/catkin_ws_2/src/easy_handeye/results/eye_on_hand/9-21--15-38.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import roboticstoolbox as rtb\n",
    "import json\n",
    "import open3d as o3d\n",
    "\n",
    "def get_to_marker_pose(image, camera_params, tag_size, detector, min_num=4):\n",
    "    '''\n",
    "    Get the pose: camera -> marker\n",
    "    '''\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    results = detector.detect(gray, estimate_tag_pose=True, camera_params=camera_params, tag_size=tag_size)\n",
    "    if len(results) < min_num:\n",
    "        return None\n",
    "    res = None\n",
    "    for result in results:\n",
    "        if result.tag_id == 22222:\n",
    "            res = result\n",
    "            break\n",
    "    if res is None:\n",
    "        return None\n",
    "    pose = np.eye(4)\n",
    "    pose[:3, :3] = res.pose_R\n",
    "    pose[:3, 3] = res.pose_t[:, 0]\n",
    "    pose = np.linalg.inv(pose)\n",
    "    hope2now = np.eye(4)\n",
    "    hope2now[1, 1] = -1\n",
    "    hope2now[2, 2] = -1\n",
    "    now2hope = np.linalg.inv(hope2now)\n",
    "    pose = now2hope @ pose \n",
    "    return pose\n",
    "\n",
    "def create_camera_model(size=0.1):\n",
    "    # Create a simple camera model (Frustum shape)\n",
    "    mesh_camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size, origin=[0, 0, 0])\n",
    "    return mesh_camera\n",
    "\n",
    "def show_pose(camera_pose, size=0.1):\n",
    "    camera_pose = np.array(camera_pose)\n",
    "    camera_pose[:3, :3] = camera_pose[:3, :3] / np.abs((np.linalg.det(camera_pose[:3, :3]))) ** (1/3)\n",
    "    # Apply camera pose transformation\n",
    "    tmp_tans = np.eye(4)\n",
    "    tmp_tans[2, 2] = -1\n",
    "    camera_model = create_camera_model(size)\n",
    "    camera_model.transform(camera_pose)\n",
    "    return camera_model\n",
    "\n",
    "def filter_and_compute_mean_std(matrices, outlier_percent=0.1):\n",
    "    \"\"\"\n",
    "    Filter out a percentage of outliers from the given matrices and compute the mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    matrices (numpy.ndarray): A numpy array of shape (n, m, m) representing n matrices of size m x m.\n",
    "    outlier_percent (float): The percentage of outliers to remove (0 < outlier_percent < 0.5), default is 10%.\n",
    "\n",
    "    Returns:\n",
    "    mean_matrix (numpy.ndarray): The mean matrix after filtering out outliers.\n",
    "    std_matrix (numpy.ndarray): The standard deviation matrix after filtering out outliers.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute the norm of each matrix\n",
    "    norms = np.linalg.norm(matrices, axis=(1, 2))\n",
    "\n",
    "    # Step 2: Sort the norms\n",
    "    sorted_indices = np.argsort(norms)\n",
    "\n",
    "    # Step 3: Compute the bounds for removing outliers\n",
    "    n_matrices = len(matrices)\n",
    "    lower_bound = int(n_matrices * outlier_percent)\n",
    "    upper_bound = int(n_matrices * (1 - outlier_percent))\n",
    "\n",
    "    # Step 4: Filter matrices\n",
    "    filtered_indices = sorted_indices[lower_bound:upper_bound]\n",
    "    filtered_matrices = matrices[filtered_indices]\n",
    "\n",
    "    # Step 5: Compute the mean and standard deviation after removing outliers\n",
    "    mean_matrix = np.mean(filtered_matrices, axis=0)\n",
    "    std_matrix = np.std(filtered_matrices, axis=0)\n",
    "\n",
    "    return mean_matrix, std_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam_EE:\n",
      "[[ 4.68582381e-04 -9.98368542e-01 -5.70967069e-02  8.01850673e-02]\n",
      " [ 9.99527826e-01  2.22178170e-03 -3.06461778e-02 -2.74386378e-02]\n",
      " [ 3.07230363e-02 -5.70553871e-02  9.97898180e-01 -8.94739605e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "Total num: 1000\n",
      "Marker_base\n",
      "[[ 6.25873131e-02  9.97268753e-01  3.92155984e-02  4.93996254e-01]\n",
      " [-9.78507076e-01  6.90506589e-02 -1.94308798e-01  1.54858690e-01]\n",
      " [-1.96485956e-01 -2.62114749e-02  9.80156226e-01  9.38567945e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "mean_marker_2_base\n",
      "[[ 6.04145342e-02  9.90460435e-01 -6.14805835e-02  4.65377361e-01]\n",
      " [-9.77241112e-01  4.70311612e-02 -2.03544594e-01  1.29829799e-01]\n",
      " [-2.01198456e-01  7.25656666e-02  9.70787614e-01 -4.16775610e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "std_marker_2_base\n",
      "[[0.0032019  0.01094724 0.10690301 0.02261133]\n",
      " [0.0063622  0.0230121  0.02806139 0.02333235]\n",
      " [0.02860671 0.10421622 0.01206026 0.0011605 ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "from pupil_apriltags import Detector\n",
    "\n",
    "log_folder = Path(log_folder)\n",
    "hdf5_file = log_folder / \"traj.hdf5\"\n",
    "hdf5_file = h5py.File(hdf5_file, 'r')\n",
    "joints = hdf5_file['joints'][:]\n",
    "timestamps = hdf5_file[\"timestamp\"][:]\n",
    "qposes = joints[:, :7]\n",
    "franka = rtb.models.Panda()\n",
    "with open(calibration_eyeinhand_results_dir, 'r') as f:\n",
    "    calibration_results = json.load(f)\n",
    "cam_2_ee = np.eye(4)\n",
    "quat = np.array([calibration_results[\"rotation\"][\"x\"], calibration_results[\"rotation\"][\"y\"], calibration_results[\"rotation\"][\"z\"], calibration_results[\"rotation\"][\"w\"]])\n",
    "cam_2_ee[:3, :3] = R.from_quat(quat, scalar_first=False).as_matrix()\n",
    "cam_2_ee[:3, 3] = np.array([calibration_results[\"translation\"][\"x\"], calibration_results[\"translation\"][\"y\"], calibration_results[\"translation\"][\"z\"]])\n",
    "print(f\"cam_EE:\\n{cam_2_ee}\")\n",
    "detector =  Detector(families=\"tagStandard52h13\",\n",
    "                    nthreads=1,\n",
    "                    quad_decimate=1.0,\n",
    "                    quad_sigma=0.0,\n",
    "                    refine_edges=1,\n",
    "                    decode_sharpening=0.25,\n",
    "                    debug=0)\n",
    "item_to_show = []\n",
    "i = 0\n",
    "import sys\n",
    "marker_2_bases = []\n",
    "print(\"Total num:\", len(qposes))\n",
    "for qpos, timestamp in zip(qposes, timestamps):\n",
    "    if i % 10 != 0 or i > 50:\n",
    "        i += 1\n",
    "        continue\n",
    "    ee_2_base = np.array(franka.fkine(qpos))\n",
    "    cam_2_base = ee_2_base @ cam_2_ee @ rtb.ET.Rz(-np.pi/2).A()\n",
    "    # ee_model = show_pose(cam_2_base, 0.1)\n",
    "    # item_to_show.append(ee_model)\n",
    "    # print(f\"timestamp: {timestamp}\")\n",
    "    # print(f\"EE_base:\\n{ee_2_base}\")\n",
    "    # print(f\"cam_base:\\n{cam_2_base}\")\n",
    "    image_path = log_folder / \"color_1/\" / f\"{timestamp}.png\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    intr = hdf5_file[\"intrinsic_color_1\"]\n",
    "    fx, fy, cx, cy = intr[\"fx\"][()], intr[\"fy\"][()], intr[\"ppx\"][()], intr[\"ppy\"][()]\n",
    "    camera_params = (fx, fy, cx, cy)\n",
    "    cam_2_maker = get_to_marker_pose(image, camera_params, 0.031, detector)\n",
    "    # print(f\"cam_marker:\\n{cam_2_maker}\")\n",
    "    if cam_2_maker is not None:\n",
    "        marker_2_base = cam_2_base @ np.linalg.inv(cam_2_maker)\n",
    "        marker_2_bases.append(marker_2_base)\n",
    "    if i == 0:\n",
    "        print(f\"Marker_base\\n{marker_2_base}\")\n",
    "    i += 1\n",
    "\n",
    "marker_2_bases = np.array(marker_2_bases)\n",
    "mean_marker_2_base, std_marker_2_base = filter_and_compute_mean_std(marker_2_bases)\n",
    "np.save(log_folder / \"marker_2_base.npy\", mean_marker_2_base)\n",
    "print(f\"mean_marker_2_base\\n{mean_marker_2_base}\")\n",
    "print(f\"std_marker_2_base\\n{std_marker_2_base}\")\n",
    "\n",
    "# frame_base = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6, origin=[0, 0, 0])\n",
    "# item_to_show.append(frame_base)\n",
    "# o3d.visualization.draw_geometries(item_to_show)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
